{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10a0231",
   "metadata": {},
   "source": [
    "# Data Colning and Data Transformation to MYSQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126e1d97",
   "metadata": {},
   "source": [
    "# Steps in the Process:\n",
    " \n",
    "01) Data Colning from Phonepe pulse data and storing it in Local Directory\n",
    "02) Extracting the necessary data from cloned data and converting them into Dataframes\n",
    "03) Performing cleaning process in the dataframe\n",
    "04) Converting each dataframe to CSV Files \n",
    "05) Connecting to MYSQL workbench and creating a phonepe database\n",
    "06) In Phonepe Databas inserting each CSV files as individual Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a5408952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [clone libraries]\n",
    "import requests\n",
    "import subprocess\n",
    "# import git\n",
    "\n",
    "# [pandas and file handling libraries]\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# [SQL libraries]\n",
    "import mysql.connector\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cdab15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git version 2.42.0.windows.2\n"
     ]
    }
   ],
   "source": [
    "!git --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "012ec033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DIVAHAR\\\\phonepe'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git --version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41d2d57",
   "metadata": {},
   "source": [
    "# Cloning process\n",
    "01) Conecting to the Git hub file repository of Phonepe Pulse\n",
    "02) Cloning the file to local directory in the computer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43500e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository cloned successfully.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Specify the GitHub repository URL\n",
    "repository_url = \"https://github.com/PhonePe/pulse.git\"\n",
    "\n",
    "# Specify the local directory where you want to clone the repository\n",
    "local_directory =\"C:/Users/DIVAHAR/phonepe/DATA\"  # Update with your desired directory\n",
    "\n",
    "# Clone the repository\n",
    "clone_command = [\"git\", \"clone\", repository_url, local_directory]\n",
    "\n",
    "try:\n",
    "    subprocess.run(clone_command, check=True)\n",
    "    print(\"Repository cloned successfully.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error cloning repository: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cd21a5",
   "metadata": {},
   "source": [
    "# Data Extraction Process\n",
    "\n",
    "01) Below this we will be extracting 6 different Data from the cloned data \n",
    "02) Each extracted Data will be unique different to each other\n",
    "03) Converting Each extracted data to individual Dataframes\n",
    "04) Perfoming Data cleaning on each dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fa1cad",
   "metadata": {},
   "source": [
    "# Aggregrated Transaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7cf45d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to clean directory names, including the specific replacement\n",
    "def clean_directory_name(dir_name):\n",
    "    dir_name = dir_name.replace(\"&\", \"and\")  # Replace '&' with 'and'\n",
    "    dir_name = dir_name.replace(\"-\", \" \")    # Replace '-' with space\n",
    "    return dir_name\n",
    "\n",
    "path1 = \"C:/Users/DIVAHAR/phonepe/DATA/data/aggregated/transaction/country/india/state\"\n",
    "agg_trans_list = os.listdir(path1)\n",
    "\n",
    "columns1 = {'State': [], 'Year': [], 'Quarter': [], 'Transaction_type': [], 'Transaction_count': [],\n",
    "            'Transaction_amount': []}\n",
    "\n",
    "for state in agg_trans_list:\n",
    "    cleaned_state = clean_directory_name(state)  # Clean the directory name\n",
    "    cur_state = os.path.join(path1, state)\n",
    "    agg_year_list = os.listdir(cur_state)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_state, year)\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            data = open(cur_file, 'r')\n",
    "            A = json.load(data)\n",
    "            \n",
    "            for i in A['data']['transactionData']:\n",
    "                name = i['name']\n",
    "                count = i['paymentInstruments'][0]['count']\n",
    "                amount = i['paymentInstruments'][0]['amount']\n",
    "                columns1['Transaction_type'].append(name)\n",
    "                columns1['Transaction_count'].append(count)\n",
    "                columns1['Transaction_amount'].append(amount)\n",
    "                columns1['State'].append(cleaned_state)  # Use the cleaned directory name\n",
    "                columns1['Year'].append(year)\n",
    "                columns1['Quarter'].append(int(file.strip('.json')))\n",
    "                \n",
    "df_agg_trans = pd.DataFrame(columns1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f066805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3954 entries, 0 to 3953\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               3954 non-null   object \n",
      " 1   Year                3954 non-null   object \n",
      " 2   Quarter             3954 non-null   int64  \n",
      " 3   Transaction_type    3954 non-null   object \n",
      " 4   Transaction_count   3954 non-null   int64  \n",
      " 5   Transaction_amount  3954 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 185.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_agg_trans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a25b1e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Transaction_type</th>\n",
       "      <th>Transaction_count</th>\n",
       "      <th>Transaction_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Recharge &amp; bill payments</td>\n",
       "      <td>4200</td>\n",
       "      <td>1.845307e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Peer-to-peer payments</td>\n",
       "      <td>1871</td>\n",
       "      <td>1.213866e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Merchant payments</td>\n",
       "      <td>298</td>\n",
       "      <td>4.525072e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>33</td>\n",
       "      <td>1.060142e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Others</td>\n",
       "      <td>256</td>\n",
       "      <td>1.846899e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>west bengal</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Merchant payments</td>\n",
       "      <td>245111000</td>\n",
       "      <td>1.767046e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>west bengal</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Peer-to-peer payments</td>\n",
       "      <td>240347041</td>\n",
       "      <td>7.970548e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>west bengal</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Recharge &amp; bill payments</td>\n",
       "      <td>58950434</td>\n",
       "      <td>3.478924e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>west bengal</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>327537</td>\n",
       "      <td>3.174670e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>west bengal</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Others</td>\n",
       "      <td>581674</td>\n",
       "      <td>4.489893e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3954 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            State  Year  Quarter          Transaction_type  \\\n",
       "0     andaman and nicobar islands  2018        1  Recharge & bill payments   \n",
       "1     andaman and nicobar islands  2018        1     Peer-to-peer payments   \n",
       "2     andaman and nicobar islands  2018        1         Merchant payments   \n",
       "3     andaman and nicobar islands  2018        1        Financial Services   \n",
       "4     andaman and nicobar islands  2018        1                    Others   \n",
       "...                           ...   ...      ...                       ...   \n",
       "3949                  west bengal  2023        2         Merchant payments   \n",
       "3950                  west bengal  2023        2     Peer-to-peer payments   \n",
       "3951                  west bengal  2023        2  Recharge & bill payments   \n",
       "3952                  west bengal  2023        2        Financial Services   \n",
       "3953                  west bengal  2023        2                    Others   \n",
       "\n",
       "      Transaction_count  Transaction_amount  \n",
       "0                  4200        1.845307e+06  \n",
       "1                  1871        1.213866e+07  \n",
       "2                   298        4.525072e+05  \n",
       "3                    33        1.060142e+04  \n",
       "4                   256        1.846899e+05  \n",
       "...                 ...                 ...  \n",
       "3949          245111000        1.767046e+11  \n",
       "3950          240347041        7.970548e+11  \n",
       "3951           58950434        3.478924e+10  \n",
       "3952             327537        3.174670e+08  \n",
       "3953             581674        4.489893e+08  \n",
       "\n",
       "[3954 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6fd2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows found in df_agg_trans.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_agg_trans is your DataFrame\n",
    "# Use the duplicated() method to identify duplicate rows\n",
    "duplicate_rows = df_agg_trans[df_agg_trans.duplicated()]\n",
    "\n",
    "# Check if there are any duplicate rows\n",
    "if duplicate_rows.shape[0] > 0:\n",
    "    print(\"Duplicate rows exist in df_agg_trans.\")\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"No duplicate rows found in df_agg_trans.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3daa3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3d640",
   "metadata": {},
   "source": [
    "## OBSERVATION:.\n",
    "\n",
    "01) Data type of state,quater,Transaction_count,Transaction_type, Transaction_amount are ok and can be remained same \n",
    "\n",
    "02) Data type of year from object to int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9d1cba0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['andaman and nicobar islands', 'andhra pradesh',\n",
       "       'arunachal pradesh', 'assam', 'bihar', 'chandigarh',\n",
       "       'chhattisgarh', 'dadra and nagar haveli and daman and diu',\n",
       "       'delhi', 'goa', 'gujarat', 'haryana', 'himachal pradesh',\n",
       "       'jammu and kashmir', 'jharkhand', 'karnataka', 'kerala', 'ladakh',\n",
       "       'lakshadweep', 'madhya pradesh', 'maharashtra', 'manipur',\n",
       "       'meghalaya', 'mizoram', 'nagaland', 'odisha', 'puducherry',\n",
       "       'punjab', 'rajasthan', 'sikkim', 'tamil nadu', 'telangana',\n",
       "       'tripura', 'uttar pradesh', 'uttarakhand', 'west bengal'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check the data type of state this can be object\n",
    "df_agg_trans['State'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bbf662b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_trans['Quarter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "898108ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    4200,     1871,      298, ..., 58950434,   327537,   581674],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_trans['Transaction_count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6810b37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Recharge & bill payments', 'Peer-to-peer payments',\n",
       "       'Merchant payments', 'Financial Services', 'Others'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_trans['Transaction_count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6db668b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2018, 2019, 2020, 2021, 2022, 2023])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_trans['Year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c401c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_trans['Year'] = df_agg_trans['Year'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70b673a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Transaction_type</th>\n",
       "      <th>Transaction_count</th>\n",
       "      <th>Transaction_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Recharge &amp; bill payments</td>\n",
       "      <td>4200</td>\n",
       "      <td>1845307.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Peer-to-peer payments</td>\n",
       "      <td>1871</td>\n",
       "      <td>12138655.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Merchant payments</td>\n",
       "      <td>298</td>\n",
       "      <td>452507.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>33</td>\n",
       "      <td>10601.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Others</td>\n",
       "      <td>256</td>\n",
       "      <td>184689.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         State  Year  Quarter          Transaction_type  \\\n",
       "0  andaman and nicobar islands  2018        1  Recharge & bill payments   \n",
       "1  andaman and nicobar islands  2018        1     Peer-to-peer payments   \n",
       "2  andaman and nicobar islands  2018        1         Merchant payments   \n",
       "3  andaman and nicobar islands  2018        1        Financial Services   \n",
       "4  andaman and nicobar islands  2018        1                    Others   \n",
       "\n",
       "   Transaction_count  Transaction_amount  \n",
       "0               4200          1845307.47  \n",
       "1               1871         12138655.30  \n",
       "2                298           452507.17  \n",
       "3                 33            10601.42  \n",
       "4                256           184689.87  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e793c93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State                  object\n",
      "Year                    int64\n",
      "Quarter                 int64\n",
      "Transaction_type       object\n",
      "Transaction_count       int64\n",
      "Transaction_amount    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "column_data_types = df_agg_trans.dtypes\n",
    "print(column_data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0bc351b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                 0\n",
       "Year                  0\n",
       "Quarter               0\n",
       "Transaction_type      0\n",
       "Transaction_count     0\n",
       "Transaction_amount    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_trans.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c9796e",
   "metadata": {},
   "source": [
    "# Aggregrated User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f5a3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to clean directory names, including the specific replacement\n",
    "def clean_directory_name(dir_name):\n",
    "    dir_name = dir_name.replace(\"&\", \"and\")  # Replace '&' with 'and'\n",
    "    dir_name = dir_name.replace(\"-\", \" \")    # Replace '-' with space\n",
    "    return dir_name\n",
    "\n",
    "path2 = \"C:\\\\Users\\\\DIVAHAR\\\\phonepe\\\\DATA\\\\data\\\\aggregated\\\\user\\\\country\\\\india\\\\state\"\n",
    "agg_user_list = os.listdir(path2)\n",
    "\n",
    "columns2 = {'State': [], 'Year': [], 'Quarter': [], 'Brands': [], 'Count': [],\n",
    "            'Percentage': []}\n",
    "\n",
    "for state in agg_user_list:\n",
    "    cleaned_state = clean_directory_name(state)  # Clean the directory name\n",
    "    cur_state = os.path.join(path2, state)\n",
    "    if not os.path.isdir(cur_state):\n",
    "        continue  # Skip non-directory entries\n",
    "\n",
    "    agg_year_list = os.listdir(cur_state)\n",
    "\n",
    "    for year in agg_year_list:\n",
    "        cleaned_year = clean_directory_name(year)  # Clean the year directory name\n",
    "        cur_year = os.path.join(cur_state, year)\n",
    "        if not os.path.isdir(cur_year):\n",
    "            continue  # Skip non-directory entries\n",
    "\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            if not os.path.isfile(cur_file):\n",
    "                continue  # Skip non-file entries\n",
    "\n",
    "            data = open(cur_file, 'r')\n",
    "            B = json.load(data)\n",
    "\n",
    "            try:\n",
    "                for i in B[\"data\"][\"usersByDevice\"]:\n",
    "                    brand_name = i[\"brand\"]\n",
    "                    counts = i[\"count\"]\n",
    "                    percents = i[\"percentage\"]\n",
    "                    columns2[\"Brands\"].append(brand_name)\n",
    "                    columns2[\"Count\"].append(counts)\n",
    "                    columns2[\"Percentage\"].append(percents)\n",
    "                    columns2[\"State\"].append(cleaned_state)\n",
    "                    columns2[\"Year\"].append(cleaned_year)\n",
    "                    columns2[\"Quarter\"].append(int(file.strip('.json')))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "df_agg_user = pd.DataFrame(columns2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1a5fb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Brands</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>1665</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>1445</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Vivo</td>\n",
       "      <td>982</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Oppo</td>\n",
       "      <td>501</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>332</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         State  Year  Quarter   Brands  Count  Percentage\n",
       "0  andaman and nicobar islands  2018        1   Xiaomi   1665        0.25\n",
       "1  andaman and nicobar islands  2018        1  Samsung   1445        0.21\n",
       "2  andaman and nicobar islands  2018        1     Vivo    982        0.15\n",
       "3  andaman and nicobar islands  2018        1     Oppo    501        0.07\n",
       "4  andaman and nicobar islands  2018        1  OnePlus    332        0.05"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c8c1ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State          object\n",
      "Year           object\n",
      "Quarter         int64\n",
      "Brands         object\n",
      "Count           int64\n",
      "Percentage    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "column_data_types = df_agg_user.dtypes\n",
    "print(column_data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cddd6a",
   "metadata": {},
   "source": [
    "## Observation :\n",
    "\n",
    "01) Datatype of year to be changed from object to int\n",
    "\n",
    "02) Datatype of other columns is ok \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8aa22616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows found in df_agg_user.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_agg_user is your DataFrame\n",
    "# Use the duplicated() method to identify duplicate rows\n",
    "duplicate_rows = df_agg_user[df_agg_user.duplicated()]\n",
    "\n",
    "# Check if there are any duplicate rows\n",
    "if duplicate_rows.shape[0] > 0:\n",
    "    print(\"Duplicate rows exist in df_agg_user.\")\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"No duplicate rows found in df_agg_user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47fc7f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_user['Year'] = df_agg_user['Year'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccd4e4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Brands</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>1665</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>1445</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Vivo</td>\n",
       "      <td>982</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Oppo</td>\n",
       "      <td>501</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>332</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         State  Year  Quarter   Brands  Count  Percentage\n",
       "0  andaman and nicobar islands  2018        1   Xiaomi   1665        0.25\n",
       "1  andaman and nicobar islands  2018        1  Samsung   1445        0.21\n",
       "2  andaman and nicobar islands  2018        1     Vivo    982        0.15\n",
       "3  andaman and nicobar islands  2018        1     Oppo    501        0.07\n",
       "4  andaman and nicobar islands  2018        1  OnePlus    332        0.05"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "263a6651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['andaman and nicobar islands', 'andhra pradesh',\n",
       "       'arunachal pradesh', 'assam', 'bihar', 'chandigarh',\n",
       "       'chhattisgarh', 'dadra and nagar haveli and daman and diu',\n",
       "       'delhi', 'goa', 'gujarat', 'haryana', 'himachal pradesh',\n",
       "       'jammu and kashmir', 'jharkhand', 'karnataka', 'kerala', 'ladakh',\n",
       "       'lakshadweep', 'madhya pradesh', 'maharashtra', 'manipur',\n",
       "       'meghalaya', 'mizoram', 'nagaland', 'odisha', 'puducherry',\n",
       "       'punjab', 'rajasthan', 'sikkim', 'tamil nadu', 'telangana',\n",
       "       'tripura', 'uttar pradesh', 'uttarakhand', 'west bengal'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_user[\"State\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb6786ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2018, 2019, 2020, 2021, 2022], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_user[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdeb4ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_user[\"Quarter\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "793090d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Xiaomi', 'Samsung', 'Vivo', 'Oppo', 'OnePlus', 'Realme', 'Apple',\n",
       "       'Motorola', 'Lenovo', 'Huawei', 'Others', 'Tecno', 'Gionee',\n",
       "       'Infinix', 'Asus', 'Micromax', 'HMD Global', 'Lava', 'COOLPAD',\n",
       "       'Lyf'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_user[\"Brands\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2eec0b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_user[\"Count\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1cdf6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_user[\"Percentage\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97dd02b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6732 entries, 0 to 6731\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   State       6732 non-null   object \n",
      " 1   Year        6732 non-null   int64  \n",
      " 2   Quarter     6732 non-null   int64  \n",
      " 3   Brands      6732 non-null   object \n",
      " 4   Count       6732 non-null   int64  \n",
      " 5   Percentage  6732 non-null   float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 315.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_agg_user.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "692fed68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State         0\n",
       "Year          0\n",
       "Quarter       0\n",
       "Brands        0\n",
       "Count         0\n",
       "Percentage    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_user.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f439e6fe",
   "metadata": {},
   "source": [
    "## Map Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "864184d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to clean directory names, including the specific replacement\n",
    "def clean_directory_name(dir_name):\n",
    "    dir_name = dir_name.replace(\"&\", \"and\")  # Replace '&' with 'and'\n",
    "    dir_name = dir_name.replace(\"-\", \" \")    # Replace '-' with space\n",
    "    return dir_name\n",
    "\n",
    "path3 = \"C:\\\\Users\\\\DIVAHAR\\\\phonepe\\\\DATA\\\\data\\\\map\\\\transaction\\\\hover\\\\country\\\\india\\\\state\"\n",
    "\n",
    "if not os.path.exists(path3):\n",
    "    print(f\"Directory '{path3}' does not exist.\")\n",
    "else:\n",
    "    map_trans_list = os.listdir(path3)\n",
    "\n",
    "    columns3 = {'State': [], 'Year': [], 'Quarter': [], 'District': [], 'Count': [],\n",
    "                'Amount': []}\n",
    "\n",
    "    for state in map_trans_list:\n",
    "        cleaned_state = clean_directory_name(state)  # Clean the directory name\n",
    "        cur_state = os.path.join(path3, state)\n",
    "        if not os.path.isdir(cur_state):\n",
    "            continue  # Skip non-directory entries\n",
    "\n",
    "        map_year_list = os.listdir(cur_state)\n",
    "\n",
    "        for year in map_year_list:\n",
    "            cleaned_year = clean_directory_name(year)  # Clean the year directory name\n",
    "            cur_year = os.path.join(cur_state, year)\n",
    "            if not os.path.isdir(cur_year):\n",
    "                continue  # Skip non-directory entries\n",
    "\n",
    "            map_file_list = os.listdir(cur_year)\n",
    "\n",
    "            for file in map_file_list:\n",
    "                cur_file = os.path.join(cur_year, file)\n",
    "                if not os.path.isfile(cur_file):\n",
    "                    continue  # Skip non-file entries\n",
    "\n",
    "                data = open(cur_file, 'r')\n",
    "                C = json.load(data)\n",
    "\n",
    "                try:\n",
    "                    for i in C[\"data\"][\"hoverDataList\"]:\n",
    "                        district = i[\"name\"]\n",
    "                        count = i[\"metric\"][0][\"count\"]\n",
    "                        amount = i[\"metric\"][0][\"amount\"]\n",
    "                        columns3[\"District\"].append(district)\n",
    "                        columns3[\"Count\"].append(count)\n",
    "                        columns3[\"Amount\"].append(amount)\n",
    "                        columns3['State'].append(cleaned_state)\n",
    "                        columns3['Year'].append(cleaned_year)\n",
    "                        columns3['Quarter'].append(int(file.strip('.json')))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    df_map_trans = pd.DataFrame(columns3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc7744ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16100 entries, 0 to 16099\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   State     16100 non-null  object \n",
      " 1   Year      16100 non-null  object \n",
      " 2   Quarter   16100 non-null  int64  \n",
      " 3   District  16100 non-null  object \n",
      " 4   Count     16100 non-null  int64  \n",
      " 5   Amount    16100 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 754.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_map_trans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f6af1",
   "metadata": {},
   "source": [
    "## Observation :\n",
    "\n",
    "01) Data type of year to be changed from object to int\n",
    "\n",
    "02) Other Column datatypes are ok \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d56b726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows found in df_map_trans.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_top_user is your DataFrame\n",
    "# Use the duplicated() method to identify duplicate rows\n",
    "duplicate_rows = df_map_trans[df_map_trans.duplicated()]\n",
    "\n",
    "# Check if there are any duplicate rows\n",
    "if duplicate_rows.shape[0] > 0:\n",
    "    print(\"Duplicate rows exist in df_map_trans.\")\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"No duplicate rows found in df_map_trans.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cc59cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['north and middle andaman district', 'south andaman district',\n",
       "       'nicobars district', 'east godavari district',\n",
       "       'srikakulam district', 'spsr nellore district',\n",
       "       'vizianagaram district', 'visakhapatnam district',\n",
       "       'prakasam district', 'anantapur district', 'ysr district',\n",
       "       'west godavari district', 'kurnool district', 'chittoor district',\n",
       "       'guntur district', 'krishna district',\n",
       "       'lower dibang valley district', 'lower subansiri district',\n",
       "       'longding district', 'west siang district', 'kamle district',\n",
       "       'upper siang district', 'tirap district', 'papum pare district',\n",
       "       'kurung kumey district', 'siang district', 'lower siang district',\n",
       "       'kra daadi district', 'changlang district',\n",
       "       'pakke kessang district', 'dibang valley district',\n",
       "       'west kameng district', 'east siang district',\n",
       "       'upper subansiri district', 'east kameng district',\n",
       "       'lohit district', 'lepa rada district', 'tawang district',\n",
       "       'namsai district', 'anjaw district', 'shi yomi district',\n",
       "       'tinsukia district', 'lakhimpur district', 'kamrup district',\n",
       "       'kokrajhar district', 'karbi anglong district',\n",
       "       'sivasagar district', 'dibrugarh district',\n",
       "       'south salmara mancachar district', 'nagaon district',\n",
       "       'dhubri district', 'golaghat district', 'udalguri district',\n",
       "       'majuli district', 'sonitpur district', 'hojai district',\n",
       "       'marigaon district', 'chirang district', 'cachar district',\n",
       "       'nalbari district', 'west karbi anglong district',\n",
       "       'dhemaji district', 'karimganj district', 'bongaigaon district',\n",
       "       'dima hasao district', 'baksa district', 'charaideo district',\n",
       "       'darrang district', 'kamrup metropolitan district',\n",
       "       'hailakandi district', 'barpeta district', 'goalpara district',\n",
       "       'biswanath district', 'jorhat district', 'madhepura district',\n",
       "       'purnia district', 'nalanda district', 'buxar district',\n",
       "       'darbhanga district', 'nawada district', 'jamui district',\n",
       "       'sheikhpura district', 'siwan district', 'muzaffarpur district',\n",
       "       'patna district', 'jehanabad district', 'rohtas district',\n",
       "       'begusarai district', 'supaul district', 'sitamarhi district',\n",
       "       'saran district', 'arwal district', 'vaishali district',\n",
       "       'pashchim champaran district', 'gopalganj district',\n",
       "       'lakhisarai district', 'aurangabad district',\n",
       "       'kaimur bhabua district', 'araria district', 'munger district',\n",
       "       'katihar district', 'khagaria district', 'saharsa district',\n",
       "       'bhagalpur district', 'madhubani district', 'kishanganj district',\n",
       "       'gaya district', 'samastipur district', 'banka district',\n",
       "       'purbi champaran district', 'sheohar district', 'bhojpur district',\n",
       "       'chandigarh district', 'dhamtari district', 'korba district',\n",
       "       'surajpur district', 'baloda bazar district', 'sukma district',\n",
       "       'raigarh district', 'janjgir champa district', 'jashpur district',\n",
       "       'balod district', 'kabirdham district', 'surguja district',\n",
       "       'dantewada district', 'gariyaband district', 'durg district',\n",
       "       'rajnandgaon district', 'raipur district', 'narayanpur district',\n",
       "       'kanker district', 'korea district', 'mungeli district',\n",
       "       'bilaspur district', 'balrampur district', 'bijapur district',\n",
       "       'bemetara district', 'bastar district', 'kondagaon district',\n",
       "       'mahasamund district', 'diu district', 'daman district',\n",
       "       'dadra and nagar haveli district', 'south district',\n",
       "       'central district', 'new delhi district', 'west district',\n",
       "       'south west district', 'south east delhi district',\n",
       "       'shahdara district', 'north east district', 'east district',\n",
       "       'north west district', 'north district', 'north goa district',\n",
       "       'south goa district', 'anand district', 'jamnagar district',\n",
       "       'devbhumi dwarka district', 'rajkot district',\n",
       "       'aravallis district', 'chhotaudepur district', 'botad district',\n",
       "       'bharuch district', 'bhavnagar district', 'junagadh district',\n",
       "       'mahesana district', 'the dangs district', 'kheda district',\n",
       "       'surat district', 'porbandar district', 'gandhinagar district',\n",
       "       'panch mahals district', 'narmada district',\n",
       "       'gir somnath district', 'valsad district', 'mahisagar district',\n",
       "       'sabar kantha district', 'tapi district', 'vadodara district',\n",
       "       'banas kantha district', 'amreli district', 'ahmadabad district',\n",
       "       'dohad district', 'navsari district', 'patan district',\n",
       "       'kachchh district', 'surendranagar district', 'morbi district',\n",
       "       'yamunanagar district', 'sonipat district', 'jind district',\n",
       "       'rohtak district', 'faridabad district', 'mahendragarh district',\n",
       "       'hisar district', 'karnal district', 'fatehabad district',\n",
       "       'palwal district', 'charkhi dadri district', 'ambala district',\n",
       "       'rewari district', 'panchkula district', 'bhiwani district',\n",
       "       'sirsa district', 'mewat district', 'panipat district',\n",
       "       'gurugram district', 'kaithal district', 'kurukshetra district',\n",
       "       'jhajjar district', 'solan district', 'sirmaur district',\n",
       "       'shimla district', 'hamirpur district', 'una district',\n",
       "       'kangra district', 'kullu district', 'mandi district',\n",
       "       'lahul and spiti district', 'chamba district', 'kinnaur district',\n",
       "       'muzaffarabad district', 'doda district', 'samba district',\n",
       "       'mirpur district', 'srinagar district', 'baramulla district',\n",
       "       'jammu district', 'ganderbal district', 'udhampur district',\n",
       "       'bandipore district', 'reasi district', 'shopian district',\n",
       "       'poonch district', 'kathua district', 'kishtwar district',\n",
       "       'pulwama district', 'ramban district', 'rajouri district',\n",
       "       'kulgam district', 'budgam district', 'anantnag district',\n",
       "       'kupwara district', 'ramgarh district', 'ranchi district',\n",
       "       'east singhbhum district', 'jamtara district', 'dumka district',\n",
       "       'koderma district', 'hazaribagh district', 'simdega district',\n",
       "       'garhwa district', 'saraikela kharsawan district',\n",
       "       'gumla district', 'chatra district', 'khunti district',\n",
       "       'dhanbad district', 'godda district', 'deoghar district',\n",
       "       'palamu district', 'latehar district', 'west singhbhum district',\n",
       "       'pakur district', 'lohardaga district', 'sahebganj district',\n",
       "       'giridih district', 'bokaro district', 'mysuru district',\n",
       "       'chitradurga district', 'kalaburagi district',\n",
       "       'ramanagara district', 'mandya district', 'kodagu district',\n",
       "       'chikkamagaluru district', 'haveri district', 'ballari district',\n",
       "       'belagavi district', 'kolar district', 'uttara kannada district',\n",
       "       'tumakuru district', 'yadgir district', 'bengaluru urban district',\n",
       "       'chikkaballapura district', 'davanagere district',\n",
       "       'bagalkote district', 'vijayapura district', 'koppal district',\n",
       "       'bidar district', 'bengaluru rural district', 'raichur district',\n",
       "       'chamarajanagara district', 'dakshina kannada district',\n",
       "       'hassan district', 'dharwad district', 'shivamogga district',\n",
       "       'udupi district', 'gadag district', 'thiruvananthapuram district',\n",
       "       'kasaragod district', 'malappuram district',\n",
       "       'pathanamthitta district', 'wayanad district',\n",
       "       'alappuzha district', 'kozhikode district', 'kollam district',\n",
       "       'thrissur district', 'palakkad district', 'kannur district',\n",
       "       'kottayam district', 'ernakulam district', 'idukki district',\n",
       "       'kargil district', 'leh ladakh district', 'lakshadweep district',\n",
       "       'morena district', 'alirajpur district', 'sehore district',\n",
       "       'rajgarh district', 'khargone district', 'satna district',\n",
       "       'narsinghpur district', 'jabalpur district',\n",
       "       'hoshangabad district', 'vidisha district', 'balaghat district',\n",
       "       'singrauli district', 'betul district', 'sidhi district',\n",
       "       'datia district', 'dewas district', 'sheopur district',\n",
       "       'neemuch district', 'raisen district', 'mandsaur district',\n",
       "       'barwani district', 'katni district', 'dindori district',\n",
       "       'shivpuri district', 'gwalior district', 'anuppur district',\n",
       "       'agar malwa district', 'ashoknagar district', 'sagar district',\n",
       "       'niwari district', 'rewa district', 'shajapur district',\n",
       "       'ujjain district', 'bhind district', 'tikamgarh district',\n",
       "       'seoni district', 'harda district', 'burhanpur district',\n",
       "       'damoh district', 'bhopal district', 'jhabua district',\n",
       "       'dhar district', 'guna district', 'east nimar district',\n",
       "       'chhindwara district', 'umaria district', 'mandla district',\n",
       "       'indore district', 'shahdol district', 'ratlam district',\n",
       "       'panna district', 'chhatarpur district', 'jalgaon district',\n",
       "       'latur district', 'thane district', 'bhandara district',\n",
       "       'nandurbar district', 'chandrapur district', 'kolhapur district',\n",
       "       'solapur district', 'mumbai district', 'sindhudurg district',\n",
       "       'dhule district', 'wardha district', 'parbhani district',\n",
       "       'mumbai suburban district', 'hingoli district',\n",
       "       'ratnagiri district', 'nanded district', 'osmanabad district',\n",
       "       'nagpur district', 'buldhana district', 'nashik district',\n",
       "       'akola district', 'yavatmal district', 'amravati district',\n",
       "       'washim district', 'sangli district', 'gadchiroli district',\n",
       "       'raigad district', 'palghar district', 'jalna district',\n",
       "       'gondia district', 'ahmednagar district', 'pune district',\n",
       "       'beed district', 'satara district', 'kangpokpi district',\n",
       "       'noney district', 'imphal east district', 'thoubal district',\n",
       "       'kakching district', 'jiribam district', 'ukhrul district',\n",
       "       'tamenglong district', 'kamjong district', 'chandel district',\n",
       "       'bishnupur district', 'senapati district', 'pherzawl district',\n",
       "       'churachandpur district', 'tengnoupal district',\n",
       "       'imphal west district', 'north garo hills district',\n",
       "       'south west khasi hills district', 'west garo hills district',\n",
       "       'south garo hills district', 'east jaintia hills district',\n",
       "       'south west garo hills district', 'east khasi hills district',\n",
       "       'east garo hills district', 'ribhoi district',\n",
       "       'west jaintia hills district', 'west khasi hills district',\n",
       "       'serchhip district', 'aizawl district', 'lunglei district',\n",
       "       'mamit district', 'lawngtlai district', 'kolasib district',\n",
       "       'champhai district', 'saiha district', 'mon district',\n",
       "       'phek district', 'longleng district', 'mokokchung district',\n",
       "       'kiphire district', 'kohima district', 'tuensang district',\n",
       "       'peren district', 'dimapur district', 'zunheboto district',\n",
       "       'wokha district', 'rayagada district', 'koraput district',\n",
       "       'malkangiri district', 'sambalpur district', 'kalahandi district',\n",
       "       'anugul district', 'ganjam district', 'jajapur district',\n",
       "       'bargarh district', 'dhenkanal district', 'bhadrak district',\n",
       "       'nuapada district', 'kendujhar district', 'mayurbhanj district',\n",
       "       'jharsuguda district', 'kandhamal district', 'deogarh district',\n",
       "       'sundargarh district', 'jagatsinghapur district',\n",
       "       'balangir district', 'baleshwar district', 'puri district',\n",
       "       'sonepur district', 'khordha district', 'boudh district',\n",
       "       'gajapati district', 'nayagarh district', 'nabarangpur district',\n",
       "       'kendrapara district', 'cuttack district', 'karaikal district',\n",
       "       'puducherry district', 'yanam district', 'mahe district',\n",
       "       'shahid bhagat singh nagar district', 'fazilka district',\n",
       "       'barnala district', 'mansa district', 'ludhiana district',\n",
       "       'sri muktsar sahib district', 'patiala district',\n",
       "       'pathankot district', 'fatehgarh sahib district',\n",
       "       'rupnagar district', 'tarn taran district', 'sas nagar district',\n",
       "       'sangrur district', 'jalandhar district', 'bathinda district',\n",
       "       'kapurthala district', 'firozepur district', 'gurdaspur district',\n",
       "       'amritsar district', 'faridkot district', 'hoshiarpur district',\n",
       "       'moga district', 'pali district', 'ganganagar district',\n",
       "       'churu district', 'jaipur district', 'baran district',\n",
       "       'bhilwara district', 'banswara district', 'dungarpur district',\n",
       "       'tonk district', 'jodhpur district', 'karauli district',\n",
       "       'udaipur district', 'dausa district', 'nagaur district',\n",
       "       'bharatpur district', 'barmer district', 'ajmer district',\n",
       "       'chittorgarh district', 'hanumangarh district',\n",
       "       'pratapgarh district', 'sawai madhopur district',\n",
       "       'jalore district', 'bikaner district', 'sikar district',\n",
       "       'dholpur district', 'sirohi district', 'rajsamand district',\n",
       "       'jaisalmer district', 'bundi district', 'jhalawar district',\n",
       "       'alwar district', 'kota district', 'jhunjhunu district',\n",
       "       'tiruchirappalli district', 'ramanathapuram district',\n",
       "       'krishnagiri district', 'cuddalore district',\n",
       "       'kancheepuram district', 'tiruppur district',\n",
       "       'dharmapuri district', 'thoothukkudi district',\n",
       "       'thanjavur district', 'madurai district',\n",
       "       'tiruvannamalai district', 'salem district',\n",
       "       'nagapattinam district', 'tirupathur district',\n",
       "       'ariyalur district', 'chennai district', 'the nilgiris district',\n",
       "       'erode district', 'karur district', 'kallakkurichi district',\n",
       "       'viluppuram district', 'pudukkottai district',\n",
       "       'perambalur district', 'coimbatore district',\n",
       "       'virudhunagar district', 'dindigul district', 'sivaganga district',\n",
       "       'tenkasi district', 'chengalpattu district',\n",
       "       'kanniyakumari district', 'tirunelveli district',\n",
       "       'thiruvallur district', 'theni district', 'ranipet district',\n",
       "       'namakkal district', 'vellore district', 'thiruvarur district',\n",
       "       'narayanpet district', 'nalgonda district', 'jangaon district',\n",
       "       'bhadradri kothagudem district', 'warangal rural district',\n",
       "       'kumuram bheem asifabad district', 'nizamabad district',\n",
       "       'adilabad district', 'rajanna sircilla district',\n",
       "       'nagarkurnool district', 'peddapalle district', 'nirmal district',\n",
       "       'mahabubabad district', 'sangareddy district',\n",
       "       'wanaparthy district', 'vikarabad district', 'jagtial district',\n",
       "       'yadadri bhuvanagiri district', 'medak district',\n",
       "       'mahbubnagar district', 'jaya shankar bhalupally district',\n",
       "       'warangal urban district', 'rangareddy district',\n",
       "       'hyderabad district', 'suryapet district',\n",
       "       'jogulamba gadwal district', 'kamareddy district',\n",
       "       'mulugu district', 'medchal malkajgiri district',\n",
       "       'karimnagar district', 'mancherial district', 'siddipet district',\n",
       "       'khammam district', 'unakoti district', 'khowai district',\n",
       "       'sepahijala district', 'north tripura district', 'dhalai district',\n",
       "       'south tripura district', 'gomati district',\n",
       "       'west tripura district', 'amethi district',\n",
       "       'siddharthnagar district', 'auraiya district', 'sambhal district',\n",
       "       'kanpur nagar district', 'aligarh district', 'mahoba district',\n",
       "       'lucknow district', 'sant kabeer nagar district',\n",
       "       'hathras district', 'budaun district', 'moradabad district',\n",
       "       'kushinagar district', 'baghpat district', 'shahjahanpur district',\n",
       "       'muzaffarnagar district', 'ambedkar nagar district',\n",
       "       'bahraich district', 'jalaun district', 'rampur district',\n",
       "       'ballia district', 'shravasti district', 'kasganj district',\n",
       "       'varanasi district', 'gautam buddha nagar district',\n",
       "       'basti district', 'shamli district', 'maharajganj district',\n",
       "       'etawah district', 'etah district', 'banda district',\n",
       "       'bijnor district', 'hardoi district', 'amroha district',\n",
       "       'pilibhit district', 'mainpuri district', 'kanpur dehat district',\n",
       "       'jaunpur district', 'kaushambi district', 'hapur district',\n",
       "       'meerut district', 'mathura district', 'chitrakoot district',\n",
       "       'lalitpur district', 'mau district', 'mirzapur district',\n",
       "       'bulandshahr district', 'gonda district', 'jhansi district',\n",
       "       'chandauli district', 'bhadohi district', 'saharanpur district',\n",
       "       'bara banki district', 'bareilly district', 'sitapur district',\n",
       "       'sultanpur district', 'agra district', 'fatehpur district',\n",
       "       'rae bareli district', 'firozabad district', 'kheri district',\n",
       "       'gorakhpur district', 'unnao district', 'prayagraj district',\n",
       "       'sonbhadra district', 'ghazipur district', 'farrukhabad district',\n",
       "       'kannauj district', 'azamgarh district', 'ayodhya district',\n",
       "       'deoria district', 'ghaziabad district', 'bageshwar district',\n",
       "       'udham singh nagar district', 'haridwar district',\n",
       "       'champawat district', 'nainital district', 'dehradun district',\n",
       "       'chamoli district', 'almora district', 'uttarkashi district',\n",
       "       'pithoragarh district', 'rudraprayag district',\n",
       "       'pauri garhwal district', 'tehri garhwal district',\n",
       "       'south twenty four parganas district', 'purba bardhaman district',\n",
       "       'uttar dinajpur district', 'kalimpong district',\n",
       "       'murshidabad district', 'paschim medinipur district',\n",
       "       'dakshin dinajpur district', 'jalpaiguri district',\n",
       "       'purulia district', 'north twenty four parganas district',\n",
       "       'bankura district', 'jhargram district', 'howrah district',\n",
       "       'hooghly district', 'kolkata district', 'koch bihar district',\n",
       "       'alipurduar district', 'paschim bardhaman district',\n",
       "       'nadia district', 'birbhum district', 'purba medinipur district',\n",
       "       'maldah district', 'darjiling district'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map_trans[\"District\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98020e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['andaman and nicobar islands', 'andhra pradesh',\n",
       "       'arunachal pradesh', 'assam', 'bihar', 'chandigarh',\n",
       "       'chhattisgarh', 'dadra and nagar haveli and daman and diu',\n",
       "       'delhi', 'goa', 'gujarat', 'haryana', 'himachal pradesh',\n",
       "       'jammu and kashmir', 'jharkhand', 'karnataka', 'kerala', 'ladakh',\n",
       "       'lakshadweep', 'madhya pradesh', 'maharashtra', 'manipur',\n",
       "       'meghalaya', 'mizoram', 'nagaland', 'odisha', 'puducherry',\n",
       "       'punjab', 'rajasthan', 'sikkim', 'tamil nadu', 'telangana',\n",
       "       'tripura', 'uttar pradesh', 'uttarakhand', 'west bengal'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map_trans[\"State\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebc592de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2018', '2019', '2020', '2021', '2022', '2023'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map_trans[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c37d07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map_trans['Year'] = df_map_trans['Year'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2eb459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16100 entries, 0 to 16099\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   State     16100 non-null  object \n",
      " 1   Year      16100 non-null  int64  \n",
      " 2   Quarter   16100 non-null  int64  \n",
      " 3   District  16100 non-null  object \n",
      " 4   Count     16100 non-null  int64  \n",
      " 5   Amount    16100 non-null  float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 754.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_map_trans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6722f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State       0\n",
       "Year        0\n",
       "Quarter     0\n",
       "District    0\n",
       "Count       0\n",
       "Amount      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map_trans.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c1e755e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>District</th>\n",
       "      <th>Count</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>north and middle andaman district</td>\n",
       "      <td>442</td>\n",
       "      <td>931663.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>south andaman district</td>\n",
       "      <td>5688</td>\n",
       "      <td>12560249.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>nicobars district</td>\n",
       "      <td>528</td>\n",
       "      <td>1139848.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>north and middle andaman district</td>\n",
       "      <td>825</td>\n",
       "      <td>1317863.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>south andaman district</td>\n",
       "      <td>9395</td>\n",
       "      <td>23948235.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         State  Year  Quarter  \\\n",
       "0  andaman and nicobar islands  2018        1   \n",
       "1  andaman and nicobar islands  2018        1   \n",
       "2  andaman and nicobar islands  2018        1   \n",
       "3  andaman and nicobar islands  2018        2   \n",
       "4  andaman and nicobar islands  2018        2   \n",
       "\n",
       "                            District  Count      Amount  \n",
       "0  north and middle andaman district    442   931663.08  \n",
       "1             south andaman district   5688 12560249.34  \n",
       "2                  nicobars district    528  1139848.80  \n",
       "3  north and middle andaman district    825  1317863.08  \n",
       "4             south andaman district   9395 23948235.52  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22d4c0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16100 entries, 0 to 16099\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   State     16100 non-null  object \n",
      " 1   Year      16100 non-null  int64  \n",
      " 2   Quarter   16100 non-null  int64  \n",
      " 3   District  16100 non-null  object \n",
      " 4   Count     16100 non-null  int64  \n",
      " 5   Amount    16100 non-null  float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 754.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_map_trans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e663f40d",
   "metadata": {},
   "source": [
    "## Map User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cb90372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to clean directory names, including the specific replacement\n",
    "def clean_directory_name(dir_name):\n",
    "    dir_name = dir_name.replace(\"&\", \"and\")  # Replace '&' with 'and'\n",
    "    dir_name = dir_name.replace(\"-\", \" \")    # Replace '-' with space\n",
    "    return dir_name\n",
    "\n",
    "path4 = \"C:\\\\Users\\\\DIVAHAR\\\\phonepe\\\\DATA\\\\data\\\\map\\\\user\\\\hover\\\\country\\\\india\\\\state\"\n",
    "\n",
    "if not os.path.exists(path4):\n",
    "    print(f\"Directory '{path4}' does not exist.\")\n",
    "else:\n",
    "    map_user_list = os.listdir(path4)\n",
    "\n",
    "    columns4 = {\"State\": [], \"Year\": [], \"Quarter\": [], \"District\": [],\n",
    "                \"RegisteredUser\": [], \"AppOpens\": []}\n",
    "\n",
    "    for state in map_user_list:\n",
    "        cleaned_state = clean_directory_name(state)  # Clean the directory name\n",
    "        cur_state = os.path.join(path4, state)\n",
    "        if not os.path.isdir(cur_state):\n",
    "            continue  # Skip non-directory entries\n",
    "\n",
    "        map_year_list = os.listdir(cur_state)\n",
    "\n",
    "        for year in map_year_list:\n",
    "            cleaned_year = clean_directory_name(year)  # Clean the year directory name\n",
    "            cur_year = os.path.join(cur_state, year)\n",
    "            if not os.path.isdir(cur_year):\n",
    "                continue  # Skip non-directory entries\n",
    "\n",
    "            map_file_list = os.listdir(cur_year)\n",
    "\n",
    "            for file in map_file_list:\n",
    "                cur_file = os.path.join(cur_year, file)\n",
    "                if not os.path.isfile(cur_file):\n",
    "                    continue  # Skip non-file entries\n",
    "\n",
    "                data = open(cur_file, 'r')\n",
    "                D = json.load(data)\n",
    "\n",
    "                try:\n",
    "                    for district, hover_data in D[\"data\"][\"hoverData\"].items():\n",
    "                        registered_user = hover_data[\"registeredUsers\"]\n",
    "                        app_opens = hover_data[\"appOpens\"]\n",
    "                        columns4[\"District\"].append(district)\n",
    "                        columns4[\"RegisteredUser\"].append(registered_user)\n",
    "                        columns4[\"AppOpens\"].append(app_opens)\n",
    "                        columns4['State'].append(cleaned_state)\n",
    "                        columns4['Year'].append(cleaned_year)\n",
    "                        columns4['Quarter'].append(int(file.strip('.json')))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    df_map_user = pd.DataFrame(columns4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c30e9f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16104 entries, 0 to 16103\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   State           16104 non-null  object\n",
      " 1   Year            16104 non-null  object\n",
      " 2   Quarter         16104 non-null  int64 \n",
      " 3   District        16104 non-null  object\n",
      " 4   RegisteredUser  16104 non-null  int64 \n",
      " 5   AppOpens        16104 non-null  int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 755.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_map_user.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c179d374",
   "metadata": {},
   "source": [
    "## Observation :\n",
    "\n",
    "01) Data type of year to be changed from object to int\n",
    "\n",
    "02) Other Column datatypes are ok \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe0a3c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows found in df_map_user.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_top_user is your DataFrame\n",
    "# Use the duplicated() method to identify duplicate rows\n",
    "duplicate_rows = df_map_user[df_map_user.duplicated()]\n",
    "\n",
    "# Check if there are any duplicate rows\n",
    "if duplicate_rows.shape[0] > 0:\n",
    "    print(\"Duplicate rows exist in df_map_user.\")\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"No duplicate rows found in df_map_user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee3e1bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>District</th>\n",
       "      <th>RegisteredUser</th>\n",
       "      <th>AppOpens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>north and middle andaman district</td>\n",
       "      <td>632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>south andaman district</td>\n",
       "      <td>5846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>nicobars district</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>north and middle andaman district</td>\n",
       "      <td>911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>south andaman district</td>\n",
       "      <td>8143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         State  Year  Quarter  \\\n",
       "0  andaman and nicobar islands  2018        1   \n",
       "1  andaman and nicobar islands  2018        1   \n",
       "2  andaman and nicobar islands  2018        1   \n",
       "3  andaman and nicobar islands  2018        2   \n",
       "4  andaman and nicobar islands  2018        2   \n",
       "\n",
       "                            District  RegisteredUser  AppOpens  \n",
       "0  north and middle andaman district             632         0  \n",
       "1             south andaman district            5846         0  \n",
       "2                  nicobars district             262         0  \n",
       "3  north and middle andaman district             911         0  \n",
       "4             south andaman district            8143         0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2dc1e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map_user['Year'] = df_map_user['Year'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a4c38c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16104 entries, 0 to 16103\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   State           16104 non-null  object\n",
      " 1   Year            16104 non-null  int64 \n",
      " 2   Quarter         16104 non-null  int64 \n",
      " 3   District        16104 non-null  object\n",
      " 4   RegisteredUser  16104 non-null  int64 \n",
      " 5   AppOpens        16104 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 755.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_map_user.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78148502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             0\n",
       "Year              0\n",
       "Quarter           0\n",
       "District          0\n",
       "RegisteredUser    0\n",
       "AppOpens          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map_user.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696826ce",
   "metadata": {},
   "source": [
    "## Top Transaction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa8fcf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to clean directory names, including the specific replacement\n",
    "def clean_directory_name(dir_name):\n",
    "    dir_name = dir_name.replace(\"&\", \"and\")  # Replace '&' with 'and'\n",
    "    dir_name = dir_name.replace(\"-\", \" \")    # Replace '-' with space\n",
    "    return dir_name\n",
    "\n",
    "path5 = \"C:\\\\Users\\\\DIVAHAR\\\\phonepe\\\\DATA\\\\data\\\\top\\\\transaction\\\\country\\\\india\\\\state\"\n",
    "\n",
    "if not os.path.exists(path5):\n",
    "    print(f\"Directory '{path5}' does not exist.\")\n",
    "else:\n",
    "    top_trans_list = os.listdir(path5)\n",
    "\n",
    "    columns5 = {'State': [], 'Year': [], 'Quarter': [], 'Pincode': [], 'Transaction_count': [],\n",
    "                'Transaction_amount': []}\n",
    "\n",
    "    for state in top_trans_list:\n",
    "        cleaned_state = clean_directory_name(state)  # Clean the directory name\n",
    "        cur_state = os.path.join(path5, state)\n",
    "        if not os.path.isdir(cur_state):\n",
    "            continue  # Skip non-directory entries\n",
    "\n",
    "        top_year_list = os.listdir(cur_state)\n",
    "\n",
    "        for year in top_year_list:\n",
    "            cleaned_year = clean_directory_name(year)  # Clean the year directory name\n",
    "            cur_year = os.path.join(cur_state, year)\n",
    "            if not os.path.isdir(cur_year):\n",
    "                continue  # Skip non-directory entries\n",
    "\n",
    "            top_file_list = os.listdir(cur_year)\n",
    "\n",
    "            for file in top_file_list:\n",
    "                cur_file = os.path.join(cur_year, file)\n",
    "                if not os.path.isfile(cur_file):\n",
    "                    continue  # Skip non-file entries\n",
    "\n",
    "                data = open(cur_file, 'r')\n",
    "                E = json.load(data)\n",
    "\n",
    "                try:\n",
    "                    for i in E['data']['pincodes']:\n",
    "                        name = i['entityName']\n",
    "                        count = i['metric']['count']\n",
    "                        amount = i['metric']['amount']\n",
    "                        columns5['Pincode'].append(name)\n",
    "                        columns5['Transaction_count'].append(count)\n",
    "                        columns5['Transaction_amount'].append(amount)\n",
    "                        columns5['State'].append(cleaned_state)\n",
    "                        columns5['Year'].append(cleaned_year)\n",
    "                        columns5['Quarter'].append(int(file.strip('.json')))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    df_top_trans = pd.DataFrame(columns5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cac9e1b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7853 entries, 0 to 7852\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               7853 non-null   object \n",
      " 1   Year                7853 non-null   object \n",
      " 2   Quarter             7853 non-null   int64  \n",
      " 3   Pincode             7851 non-null   object \n",
      " 4   Transaction_count   7853 non-null   int64  \n",
      " 5   Transaction_amount  7853 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 368.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_top_trans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c551aa5",
   "metadata": {},
   "source": [
    "# Observation : \n",
    "01) Year datatype to be changed from object to int \n",
    "02) Two missing values are found in Picode column which need to be attended \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ab82342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows found in df_top_trans.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_top_user is your DataFrame\n",
    "# Use the duplicated() method to identify duplicate rows\n",
    "duplicate_rows = df_top_trans[df_top_trans.duplicated()]\n",
    "\n",
    "# Check if there are any duplicate rows\n",
    "if duplicate_rows.shape[0] > 0:\n",
    "    print(\"Duplicate rows exist in df_top_trans.\")\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"No duplicate rows found in df_top_trans.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0788458",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Pincode</th>\n",
       "      <th>Transaction_count</th>\n",
       "      <th>Transaction_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744101</td>\n",
       "      <td>1622</td>\n",
       "      <td>2769297.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744103</td>\n",
       "      <td>1223</td>\n",
       "      <td>2238041.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744102</td>\n",
       "      <td>969</td>\n",
       "      <td>3519059.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744105</td>\n",
       "      <td>685</td>\n",
       "      <td>1298560.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744104</td>\n",
       "      <td>340</td>\n",
       "      <td>1039715.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         State  Year  Quarter Pincode  Transaction_count  \\\n",
       "0  andaman and nicobar islands  2018        1  744101               1622   \n",
       "1  andaman and nicobar islands  2018        1  744103               1223   \n",
       "2  andaman and nicobar islands  2018        1  744102                969   \n",
       "3  andaman and nicobar islands  2018        1  744105                685   \n",
       "4  andaman and nicobar islands  2018        1  744104                340   \n",
       "\n",
       "   Transaction_amount  \n",
       "0          2769297.90  \n",
       "1          2238041.87  \n",
       "2          3519059.94  \n",
       "3          1298560.95  \n",
       "4          1039715.31  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d2c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Data type of year column to integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77daa36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_trans['Year'] = df_top_trans['Year'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba4e8ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cab9f9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Pincode</th>\n",
       "      <th>Transaction_count</th>\n",
       "      <th>Transaction_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744101</td>\n",
       "      <td>1622</td>\n",
       "      <td>2769297.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744103</td>\n",
       "      <td>1223</td>\n",
       "      <td>2238041.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744102</td>\n",
       "      <td>969</td>\n",
       "      <td>3519059.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744105</td>\n",
       "      <td>685</td>\n",
       "      <td>1298560.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andaman and nicobar islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744104</td>\n",
       "      <td>340</td>\n",
       "      <td>1039715.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         State  Year  Quarter Pincode  Transaction_count  \\\n",
       "0  andaman and nicobar islands  2018        1  744101               1622   \n",
       "1  andaman and nicobar islands  2018        1  744103               1223   \n",
       "2  andaman and nicobar islands  2018        1  744102                969   \n",
       "3  andaman and nicobar islands  2018        1  744105                685   \n",
       "4  andaman and nicobar islands  2018        1  744104                340   \n",
       "\n",
       "   Transaction_amount  \n",
       "0          2769297.90  \n",
       "1          2238041.87  \n",
       "2          3519059.94  \n",
       "3          1298560.95  \n",
       "4          1039715.31  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf74bbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7853, 6)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bfae1491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7853 entries, 0 to 7852\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               7853 non-null   object \n",
      " 1   Year                7853 non-null   int64  \n",
      " 2   Quarter             7853 non-null   int64  \n",
      " 3   Pincode             7851 non-null   object \n",
      " 4   Transaction_count   7853 non-null   int64  \n",
      " 5   Transaction_amount  7853 non-null   float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 368.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_top_trans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad3eb380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                 0\n",
       "Year                  0\n",
       "Quarter               0\n",
       "Pincode               2\n",
       "Transaction_count     0\n",
       "Transaction_amount    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_trans.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83b3a33d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['andaman and nicobar islands', 'andhra pradesh',\n",
       "       'arunachal pradesh', 'assam', 'bihar', 'chandigarh',\n",
       "       'chhattisgarh', 'dadra and nagar haveli and daman and diu',\n",
       "       'delhi', 'goa', 'gujarat', 'haryana', 'himachal pradesh',\n",
       "       'jammu and kashmir', 'jharkhand', 'karnataka', 'kerala', 'ladakh',\n",
       "       'lakshadweep', 'madhya pradesh', 'maharashtra', 'manipur',\n",
       "       'meghalaya', 'mizoram', 'nagaland', 'odisha', 'puducherry',\n",
       "       'punjab', 'rajasthan', 'sikkim', 'tamil nadu', 'telangana',\n",
       "       'tripura', 'uttar pradesh', 'uttarakhand', 'west bengal'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_trans['State'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "24d0131f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2018, 2019, 2020, 2021, 2022, 2023], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_trans['Year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae548e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_trans['Quarter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16d81cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_trans['Quarter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "815d3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see which row has missing Pincode values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "44e4ff96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Pincode</th>\n",
       "      <th>Transaction_count</th>\n",
       "      <th>Transaction_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>2014</td>\n",
       "      <td>10098656.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>13717</td>\n",
       "      <td>36711603.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State  Year  Quarter Pincode  Transaction_count  Transaction_amount\n",
       "3794  ladakh  2019        4    None               2014         10098656.17\n",
       "3836  ladakh  2020        4    None              13717         36711603.92"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_none_pincode = df_top_trans[df_top_trans['Pincode'].isna()]\n",
    "rows_with_none_pincode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "185b0416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Pincode</th>\n",
       "      <th>Transaction_count</th>\n",
       "      <th>Transaction_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>194101</td>\n",
       "      <td>6526</td>\n",
       "      <td>23776399.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>194102</td>\n",
       "      <td>1799</td>\n",
       "      <td>6137851.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>194103</td>\n",
       "      <td>2115</td>\n",
       "      <td>7315736.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>194104</td>\n",
       "      <td>9100</td>\n",
       "      <td>32131162.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>194105</td>\n",
       "      <td>2051</td>\n",
       "      <td>7670728.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>194106</td>\n",
       "      <td>1181</td>\n",
       "      <td>5266777.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>194107</td>\n",
       "      <td>5228</td>\n",
       "      <td>21335611.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>194201</td>\n",
       "      <td>3905</td>\n",
       "      <td>16456855.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>194401</td>\n",
       "      <td>693</td>\n",
       "      <td>3798802.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>194703</td>\n",
       "      <td>1965</td>\n",
       "      <td>9248371.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>194101</td>\n",
       "      <td>19933</td>\n",
       "      <td>73175814.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>194102</td>\n",
       "      <td>903</td>\n",
       "      <td>4245135.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>194103</td>\n",
       "      <td>1521</td>\n",
       "      <td>7432483.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>194104</td>\n",
       "      <td>25677</td>\n",
       "      <td>93804173.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>194106</td>\n",
       "      <td>4376</td>\n",
       "      <td>18102525.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>194107</td>\n",
       "      <td>8728</td>\n",
       "      <td>34212482.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>194109</td>\n",
       "      <td>1035</td>\n",
       "      <td>4422891.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>194201</td>\n",
       "      <td>12715</td>\n",
       "      <td>46549944.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>194401</td>\n",
       "      <td>5372</td>\n",
       "      <td>23507363.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>2014</td>\n",
       "      <td>10098656.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>194101</td>\n",
       "      <td>53569</td>\n",
       "      <td>186455975.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>194102</td>\n",
       "      <td>17941</td>\n",
       "      <td>61946061.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>194103</td>\n",
       "      <td>19884</td>\n",
       "      <td>63335720.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>194104</td>\n",
       "      <td>79598</td>\n",
       "      <td>265446627.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>194106</td>\n",
       "      <td>13802</td>\n",
       "      <td>37001878.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>194107</td>\n",
       "      <td>28650</td>\n",
       "      <td>101994102.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>194201</td>\n",
       "      <td>40398</td>\n",
       "      <td>145874101.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>194401</td>\n",
       "      <td>19253</td>\n",
       "      <td>76107254.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>194703</td>\n",
       "      <td>12137</td>\n",
       "      <td>41598849.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>13717</td>\n",
       "      <td>36711603.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>194101</td>\n",
       "      <td>145867</td>\n",
       "      <td>501529595.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>194102</td>\n",
       "      <td>31783</td>\n",
       "      <td>110979297.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3873</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>194103</td>\n",
       "      <td>36689</td>\n",
       "      <td>112442870.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>194104</td>\n",
       "      <td>152915</td>\n",
       "      <td>482150693.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3875</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>194105</td>\n",
       "      <td>22207</td>\n",
       "      <td>67216234.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>194106</td>\n",
       "      <td>17704</td>\n",
       "      <td>56842594.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>194107</td>\n",
       "      <td>38000</td>\n",
       "      <td>139391735.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>194201</td>\n",
       "      <td>74027</td>\n",
       "      <td>274189707.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>194401</td>\n",
       "      <td>43146</td>\n",
       "      <td>168530928.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>194703</td>\n",
       "      <td>21830</td>\n",
       "      <td>68873210.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>194101</td>\n",
       "      <td>242758</td>\n",
       "      <td>650642182.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>194102</td>\n",
       "      <td>55644</td>\n",
       "      <td>138011380.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>194103</td>\n",
       "      <td>62642</td>\n",
       "      <td>136252415.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>194104</td>\n",
       "      <td>253102</td>\n",
       "      <td>634954359.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>194105</td>\n",
       "      <td>41674</td>\n",
       "      <td>98531402.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3914</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>194107</td>\n",
       "      <td>54757</td>\n",
       "      <td>143326775.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>194201</td>\n",
       "      <td>128329</td>\n",
       "      <td>361948632.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3911</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>194401</td>\n",
       "      <td>73153</td>\n",
       "      <td>227090234.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>194404</td>\n",
       "      <td>50950</td>\n",
       "      <td>195859048.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>194703</td>\n",
       "      <td>34085</td>\n",
       "      <td>90457957.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State  Year  Quarter Pincode  Transaction_count  Transaction_amount\n",
       "3749  ladakh  2018        4  194101               6526         23776399.25\n",
       "3755  ladakh  2018        4  194102               1799          6137851.00\n",
       "3752  ladakh  2018        4  194103               2115          7315736.67\n",
       "3748  ladakh  2018        4  194104               9100         32131162.60\n",
       "3753  ladakh  2018        4  194105               2051          7670728.19\n",
       "3756  ladakh  2018        4  194106               1181          5266777.98\n",
       "3750  ladakh  2018        4  194107               5228         21335611.27\n",
       "3751  ladakh  2018        4  194201               3905         16456855.18\n",
       "3757  ladakh  2018        4  194401                693          3798802.39\n",
       "3754  ladakh  2018        4  194703               1965          9248371.78\n",
       "3789  ladakh  2019        4  194101              19933         73175814.13\n",
       "3797  ladakh  2019        4  194102                903          4245135.13\n",
       "3795  ladakh  2019        4  194103               1521          7432483.44\n",
       "3788  ladakh  2019        4  194104              25677         93804173.45\n",
       "3793  ladakh  2019        4  194106               4376         18102525.17\n",
       "3791  ladakh  2019        4  194107               8728         34212482.95\n",
       "3796  ladakh  2019        4  194109               1035          4422891.10\n",
       "3790  ladakh  2019        4  194201              12715         46549944.53\n",
       "3792  ladakh  2019        4  194401               5372         23507363.89\n",
       "3794  ladakh  2019        4    None               2014         10098656.17\n",
       "3829  ladakh  2020        4  194101              53569        186455975.80\n",
       "3834  ladakh  2020        4  194102              17941         61946061.19\n",
       "3832  ladakh  2020        4  194103              19884         63335720.98\n",
       "3828  ladakh  2020        4  194104              79598        265446627.74\n",
       "3835  ladakh  2020        4  194106              13802         37001878.33\n",
       "3831  ladakh  2020        4  194107              28650        101994102.21\n",
       "3830  ladakh  2020        4  194201              40398        145874101.04\n",
       "3833  ladakh  2020        4  194401              19253         76107254.40\n",
       "3837  ladakh  2020        4  194703              12137         41598849.49\n",
       "3836  ladakh  2020        4    None              13717         36711603.92\n",
       "3869  ladakh  2021        4  194101             145867        501529595.88\n",
       "3874  ladakh  2021        4  194102              31783        110979297.21\n",
       "3873  ladakh  2021        4  194103              36689        112442870.84\n",
       "3868  ladakh  2021        4  194104             152915        482150693.81\n",
       "3875  ladakh  2021        4  194105              22207         67216234.07\n",
       "3877  ladakh  2021        4  194106              17704         56842594.13\n",
       "3872  ladakh  2021        4  194107              38000        139391735.74\n",
       "3870  ladakh  2021        4  194201              74027        274189707.01\n",
       "3871  ladakh  2021        4  194401              43146        168530928.87\n",
       "3876  ladakh  2021        4  194703              21830         68873210.48\n",
       "3909  ladakh  2022        4  194101             242758        650642182.72\n",
       "3913  ladakh  2022        4  194102              55644        138011380.53\n",
       "3912  ladakh  2022        4  194103              62642        136252415.72\n",
       "3908  ladakh  2022        4  194104             253102        634954359.60\n",
       "3916  ladakh  2022        4  194105              41674         98531402.32\n",
       "3914  ladakh  2022        4  194107              54757        143326775.18\n",
       "3910  ladakh  2022        4  194201             128329        361948632.45\n",
       "3911  ladakh  2022        4  194401              73153        227090234.79\n",
       "3915  ladakh  2022        4  194404              50950        195859048.50\n",
       "3917  ladakh  2022        4  194703              34085         90457957.40"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ladakh_quarter_4_rows = df_top_trans[(df_top_trans['State'] == 'ladakh') & (df_top_trans['Quarter'] == 4)]\n",
    "ladakh_quarter_4_rows = ladakh_quarter_4_rows.sort_values(by=['Year','Pincode'] )\n",
    "ladakh_quarter_4_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6482234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing values based on the repeative pincode in ladakh and quater = 4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20093025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_trans['Pincode'].fillna('194105', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4f9f3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7853 entries, 0 to 7852\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               7853 non-null   object \n",
      " 1   Year                7853 non-null   int64  \n",
      " 2   Quarter             7853 non-null   int64  \n",
      " 3   Pincode             7853 non-null   object \n",
      " 4   Transaction_count   7853 non-null   int64  \n",
      " 5   Transaction_amount  7853 non-null   float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 368.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_top_trans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2507bbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                 0\n",
       "Year                  0\n",
       "Quarter               0\n",
       "Pincode               0\n",
       "Transaction_count     0\n",
       "Transaction_amount    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_trans.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "80c84a98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['194101', '194102', '194103', '194104', '194105', '194106',\n",
       "       '194107', '194201', '194401', '194703', '194109', None, '194404'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ladakh_quarter_4_rows['Pincode'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9270568b",
   "metadata": {},
   "source": [
    "## Top User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "043f3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to clean directory names, including the specific replacement\n",
    "def clean_directory_name(dir_name):\n",
    "    dir_name = dir_name.replace(\"&\", \"and\")  # Replace '&' with 'and'\n",
    "    dir_name = dir_name.replace(\"-\", \" \")    # Replace '-' with space\n",
    "    return dir_name\n",
    "\n",
    "# Specify the directory path\n",
    "path6 = \"C:\\\\Users\\\\DIVAHAR\\\\phonepe\\\\DATA\\\\data\\\\top\\\\user\\\\country\\\\india\\\\state\"\n",
    "\n",
    "if not os.path.exists(path6):\n",
    "    print(f\"Directory '{path6}' does not exist.\")\n",
    "else:\n",
    "    top_user_list = os.listdir(path6)\n",
    "\n",
    "    columns6 = {'State': [], 'Year': [], 'Quarter': [], 'Pincode': [], 'RegisteredUsers': []}\n",
    "\n",
    "    for state in top_user_list:\n",
    "        cur_state = os.path.join(path6, state)\n",
    "        if not os.path.isdir(cur_state):\n",
    "            continue  # Skip non-directory entries\n",
    "\n",
    "        top_year_list = os.listdir(cur_state)\n",
    "\n",
    "        for year in top_year_list:\n",
    "            cur_year = os.path.join(cur_state, year)\n",
    "            if not os.path.isdir(cur_year):\n",
    "                continue  # Skip non-directory entries\n",
    "\n",
    "            top_file_list = os.listdir(cur_year)\n",
    "\n",
    "            for file in top_file_list:\n",
    "                cur_file = os.path.join(cur_year, file)\n",
    "                if not os.path.isfile(cur_file):\n",
    "                    continue  # Skip non-file entries\n",
    "\n",
    "                data = open(cur_file, 'r')\n",
    "                F = json.load(data)\n",
    "\n",
    "                try:\n",
    "                    for i in F['data']['pincodes']:\n",
    "                        name = i['name']\n",
    "                        registeredUsers = i['registeredUsers']\n",
    "                        columns6['Pincode'].append(name)\n",
    "                        columns6['RegisteredUsers'].append(registeredUsers)\n",
    "                        columns6['State'].append(state)\n",
    "                        columns6['Year'].append(year)\n",
    "                        columns6['Quarter'].append(int(file.strip('.json')))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    df_top_user = pd.DataFrame(columns6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c655e080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7854 entries, 0 to 7853\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   State            7854 non-null   object\n",
      " 1   Year             7854 non-null   object\n",
      " 2   Quarter          7854 non-null   int64 \n",
      " 3   Pincode          7854 non-null   object\n",
      " 4   RegisteredUsers  7854 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 306.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_top_user.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b92a4b",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "\n",
    "01) Year and Pincode Data Type to be changed from object to int\n",
    "\n",
    "02) State,quater,RegisteredUsers  data type is good and can be proceed further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bd27186d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State              0\n",
       "Year               0\n",
       "Quarter            0\n",
       "Pincode            0\n",
       "RegisteredUsers    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_user.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "089217e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Pincode</th>\n",
       "      <th>RegisteredUsers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andaman-&amp;-nicobar-islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744103</td>\n",
       "      <td>1608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andaman-&amp;-nicobar-islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744101</td>\n",
       "      <td>1108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andaman-&amp;-nicobar-islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744105</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andaman-&amp;-nicobar-islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744102</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andaman-&amp;-nicobar-islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>744104</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       State  Year  Quarter Pincode  RegisteredUsers\n",
       "0  andaman-&-nicobar-islands  2018        1  744103             1608\n",
       "1  andaman-&-nicobar-islands  2018        1  744101             1108\n",
       "2  andaman-&-nicobar-islands  2018        1  744105             1075\n",
       "3  andaman-&-nicobar-islands  2018        1  744102             1006\n",
       "4  andaman-&-nicobar-islands  2018        1  744104              272"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0ddf3dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['andaman-&-nicobar-islands', 'andhra-pradesh', 'arunachal-pradesh',\n",
       "       'assam', 'bihar', 'chandigarh', 'chhattisgarh',\n",
       "       'dadra-&-nagar-haveli-&-daman-&-diu', 'delhi', 'goa', 'gujarat',\n",
       "       'haryana', 'himachal-pradesh', 'jammu-&-kashmir', 'jharkhand',\n",
       "       'karnataka', 'kerala', 'ladakh', 'lakshadweep', 'madhya-pradesh',\n",
       "       'maharashtra', 'manipur', 'meghalaya', 'mizoram', 'nagaland',\n",
       "       'odisha', 'puducherry', 'punjab', 'rajasthan', 'sikkim',\n",
       "       'tamil-nadu', 'telangana', 'tripura', 'uttar-pradesh',\n",
       "       'uttarakhand', 'west-bengal'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_user['State'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2953de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_user['State'] = df_top_user['State'].apply(clean_directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2a499b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['andaman and nicobar islands', 'andhra pradesh',\n",
       "       'arunachal pradesh', 'assam', 'bihar', 'chandigarh',\n",
       "       'chhattisgarh', 'dadra and nagar haveli and daman and diu',\n",
       "       'delhi', 'goa', 'gujarat', 'haryana', 'himachal pradesh',\n",
       "       'jammu and kashmir', 'jharkhand', 'karnataka', 'kerala', 'ladakh',\n",
       "       'lakshadweep', 'madhya pradesh', 'maharashtra', 'manipur',\n",
       "       'meghalaya', 'mizoram', 'nagaland', 'odisha', 'puducherry',\n",
       "       'punjab', 'rajasthan', 'sikkim', 'tamil nadu', 'telangana',\n",
       "       'tripura', 'uttar pradesh', 'uttarakhand', 'west bengal'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_user['State'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf1e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverting Datatype of year and Pincode to int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "76e495fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_user['Year'] = df_top_user['Year'].astype('int64')\n",
    "df_top_user['Pincode'] = df_top_user['Pincode'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c6ba4368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7854 entries, 0 to 7853\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   State            7854 non-null   object\n",
      " 1   Year             7854 non-null   int64 \n",
      " 2   Quarter          7854 non-null   int64 \n",
      " 3   Pincode          7854 non-null   int64 \n",
      " 4   RegisteredUsers  7854 non-null   int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 306.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_top_user.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39580634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows found in df_top_user.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_top_user is your DataFrame\n",
    "# Use the duplicated() method to identify duplicate rows\n",
    "duplicate_rows = df_top_user[df_top_user.duplicated()]\n",
    "\n",
    "# Check if there are any duplicate rows\n",
    "if duplicate_rows.shape[0] > 0:\n",
    "    print(\"Duplicate rows exist in df_top_user.\")\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"No duplicate rows found in df_top_user.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c07ba",
   "metadata": {},
   "source": [
    "# Data Transforming Process\n",
    "\n",
    "## Coverting all data frames to CSV Files\n",
    "\n",
    "01) Each Extracted Dataframe to be saved a individual csv files\n",
    "02) This CSV file will later be inserted into MY SQL workbech for visualiation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e3517621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_top_user is your DataFrame\n",
    "# Specify the file path where you want to save the CSV file\n",
    "csv_file_path = 'df_agg_trans.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_agg_trans.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Replace 'csv_file_path' with the desired file path where you want to save the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1b11d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_top_user is your DataFrame\n",
    "# Specify the file path where you want to save the CSV file\n",
    "csv_file_path = 'df_agg_user.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_agg_user.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Replace 'csv_file_path' with the desired file path where you want to save the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "72d380ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_top_user is your DataFrame\n",
    "# Specify the file path where you want to save the CSV file\n",
    "csv_file_path = 'df_map_trans.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_map_trans.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Replace 'csv_file_path' with the desired file path where you want to save the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0effeb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_top_user is your DataFrame\n",
    "# Specify the file path where you want to save the CSV file\n",
    "csv_file_path = 'df_map_user.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_map_user.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Replace 'csv_file_path' with the desired file path where you want to save the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "364d78c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_top_user is your DataFrame\n",
    "# Specify the file path where you want to save the CSV file\n",
    "csv_file_path = 'df_top_trans.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_top_trans.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Replace 'csv_file_path' with the desired file path where you want to save the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7737fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_top_user is your DataFrame\n",
    "# Specify the file path where you want to save the CSV file\n",
    "csv_file_path = 'df_top_user.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_top_user.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Replace 'csv_file_path' with the desired file path where you want to save the CSV file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8842cb",
   "metadata": {},
   "source": [
    "# Connection to  MY SQL Workbench\n",
    "01) Create a Phonepe database in mysql \n",
    "02) Create individual tables with respect to each csv files and the columns data types\n",
    "03) inserting the vaules in each csv file in their respective tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5cfcaf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Define your MySQL connection parameters\n",
    "mysql_config = {\n",
    "    'host': '127.0.0.1',       # Replace with your MySQL host\n",
    "    'user': 'root',   # Replace with your MySQL username\n",
    "    'password': '1234' # Replace with your MySQL password\n",
    "}\n",
    "\n",
    "# Create a connection to MySQL\n",
    "connection = mysql.connector.connect(**mysql_config)\n",
    "\n",
    "# Create a cursor object to execute SQL commands\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Create the \"phonepe\" database\n",
    "cursor.execute(\"CREATE DATABASE IF NOT EXISTS phonepe\")\n",
    "\n",
    "# Close the cursor and MySQL connection\n",
    "cursor.close()\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c476fc8c",
   "metadata": {},
   "source": [
    "## df_agg_trans csv to mysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9886c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df_agg_trans = pd.read_csv('df_agg_trans.csv')\n",
    "\n",
    "\n",
    "# Establish a MySQL database connection\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=\"1234\",\n",
    "    database=\"phonepe\" \n",
    ")\n",
    "\n",
    "# Create a cursor\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# Define the table creation SQL query\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS df_agg_trans (\n",
    "    State VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    Transaction_type VARCHAR(255),\n",
    "    Transaction_count INT,\n",
    "    Transaction_amount DOUBLE\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Execute the table creation query\n",
    "mycursor.execute(create_table_query)\n",
    "\n",
    "# Insert data from the DataFrame into the table\n",
    "for _, row in df_agg_trans.iterrows():\n",
    "    insert_query = \"INSERT INTO df_agg_trans (State, Year, Quarter, Transaction_type, Transaction_count, Transaction_amount) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "    values = (row['State'], row['Year'], row['Quarter'], row['Transaction_type'], row['Transaction_count'], round(row['Transaction_amount'], 4))\n",
    "    mycursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes to the database\n",
    "mydb.commit()\n",
    "\n",
    "# Close the cursor and the database connection\n",
    "mycursor.close()\n",
    "mydb.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f5903",
   "metadata": {},
   "source": [
    "## df_agg_user csv to mysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a0523094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df_agg_trans = pd.read_csv('df_agg_user.csv')\n",
    "\n",
    "# Establish a MySQL database connection\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=\"1234\",\n",
    "    database=\"phonepe\" \n",
    ")\n",
    "\n",
    "# Create a cursor\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# Define the table creation SQL query\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS df_agg_user (\n",
    "    State VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    Brands VARCHAR(255),\n",
    "    Count INT,\n",
    "    Percentage DOUBLE\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Execute the table creation query\n",
    "mycursor.execute(create_table_query)\n",
    "\n",
    "# Insert data from the DataFrame into the table\n",
    "for _, row in df_agg_trans.iterrows():\n",
    "    insert_query = \"INSERT INTO df_agg_user (State, Year, Quarter, Brands, Count, Percentage) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "    values = (row['State'], row['Year'], row['Quarter'], row['Brands'], row['Count'], row['Percentage'])\n",
    "    mycursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes to the database\n",
    "mydb.commit()\n",
    "\n",
    "# Close the cursor and the database connection\n",
    "mycursor.close()\n",
    "mydb.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3755c6",
   "metadata": {},
   "source": [
    "# map trans csv to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dca823bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df_map_trans = pd.read_csv('df_map_trans.csv')\n",
    "\n",
    "# Establish a MySQL database connection\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=\"1234\",\n",
    "    database=\"phonepe\"\n",
    ")\n",
    "\n",
    "# Create a cursor\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# Define the table creation SQL query\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS df_map_trans (\n",
    "    State VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    District VARCHAR(255),\n",
    "    Count INT,\n",
    "    Amount DOUBLE\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Execute the table creation query\n",
    "mycursor.execute(create_table_query)\n",
    "\n",
    "# Insert data from the DataFrame into the table\n",
    "for _, row in df_map_trans.iterrows():\n",
    "    insert_query = \"INSERT INTO df_map_trans (State, Year, Quarter, District, Count, Amount) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "    values = (row['State'], row['Year'], row['Quarter'], row['District'], row['Count'], row['Amount'])\n",
    "    mycursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes to the database\n",
    "mydb.commit()\n",
    "\n",
    "# Close the cursor and the database connection\n",
    "mycursor.close()\n",
    "mydb.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab1f72",
   "metadata": {},
   "source": [
    "# map user csv to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "26079a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df_map_user = pd.read_csv('df_map_user.csv')\n",
    "\n",
    "# Establish a MySQL database connection\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=\"1234\",\n",
    "    database=\"phonepe\"\n",
    ")\n",
    "\n",
    "# Create a cursor\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# Define the table creation SQL query\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS df_map_user (\n",
    "    State VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    District VARCHAR(255),\n",
    "    RegisteredUser INT,\n",
    "    AppOpens INT\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Execute the table creation query\n",
    "mycursor.execute(create_table_query)\n",
    "\n",
    "# Insert data from the DataFrame into the table\n",
    "for _, row in df_map_user.iterrows():\n",
    "    insert_query = \"INSERT INTO df_map_user (State, Year, Quarter, District, RegisteredUser, AppOpens) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "    values = (row['State'], row['Year'], row['Quarter'], row['District'], row['RegisteredUser'], row['AppOpens'])\n",
    "    mycursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes to the database\n",
    "mydb.commit()\n",
    "\n",
    "# Close the cursor and the database connection\n",
    "mycursor.close()\n",
    "mydb.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f76a94",
   "metadata": {},
   "source": [
    "# df_top_tans csv to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b2f57ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df_top_trans = pd.read_csv('df_top_trans.csv')\n",
    "\n",
    "# Establish a MySQL database connection\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=\"1234\",\n",
    "    database=\"phonepe\"\n",
    ")\n",
    "\n",
    "# Create a cursor\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# Define the table creation SQL query\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS df_top_trans (\n",
    "    State VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    Pincode VARCHAR(255),\n",
    "    Transaction_count INT,\n",
    "    Transaction_amount DOUBLE\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Execute the table creation query\n",
    "mycursor.execute(create_table_query)\n",
    "\n",
    "# Insert data from the DataFrame into the table\n",
    "for _, row in df_top_trans.iterrows():\n",
    "    insert_query = \"INSERT INTO df_top_trans (State, Year, Quarter, Pincode, Transaction_count, Transaction_amount) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "    values = (row['State'], row['Year'], row['Quarter'], row['Pincode'], row['Transaction_count'], round(row['Transaction_amount'], 4))\n",
    "    mycursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes to the database\n",
    "mydb.commit()\n",
    "\n",
    "# Close the cursor and the database connection\n",
    "mycursor.close()\n",
    "mydb.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a553a1",
   "metadata": {},
   "source": [
    "# df_top_user csv to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5c2cfb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df_top_user = pd.read_csv('df_top_user.csv')\n",
    "\n",
    "# Establish a MySQL database connection\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=\"1234\",\n",
    "    database=\"phonepe\"\n",
    ")\n",
    "\n",
    "# Create a cursor\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# Define the table creation SQL query\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS df_top_user (\n",
    "    State VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    Pincode INT,\n",
    "    RegisteredUsers INT\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Execute the table creation query\n",
    "mycursor.execute(create_table_query)\n",
    "\n",
    "# Insert data from the DataFrame into the table\n",
    "for _, row in df_top_user.iterrows():\n",
    "    insert_query = \"INSERT INTO df_top_user (State, Year, Quarter, Pincode, RegisteredUsers) VALUES (%s, %s, %s, %s, %s)\"\n",
    "    values = (row['State'], row['Year'], row['Quarter'], row['Pincode'], row['RegisteredUsers'])\n",
    "    mycursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes to the database\n",
    "mydb.commit()\n",
    "\n",
    "# Close the cursor and the database connection\n",
    "mycursor.close()\n",
    "mydb.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c97df2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
